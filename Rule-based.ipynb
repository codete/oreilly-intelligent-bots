{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building intelligent bots. Rule-based chatbots\n",
    "\n",
    "This section consist of major topics related to rule-based chatbots. One of the most important topic are the similarity methods for word and sentences. It contains a short use case of regular expressions for sentence parsing. We show the differences between LIKE and full-text search that are used in SQL databases. A major topic included in this section are NLP methods that can be used for easier sentence comparison. Finally, we build a simple example of questions and answers that can be used by chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and sentences similarity\n",
    "\n",
    "Word does have different meanings. This makes the comparison and analysis a bit more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "\n",
    "w = Word(\"developer\")\n",
    "\n",
    "for synset, definition in zip(w.get_synsets(), w.define()):\n",
    "    print(synset, definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expressions\n",
    "\n",
    "Regular expressions are commonly used for string manipulation and are often used behind many other high-level string manipulations methods. Below we show a use case of parsing the strings for SQL queries. We use this example later for LIKE keyword and full-text search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3, csv, re\n",
    "\n",
    "# load the dataset\n",
    "conn = sqlite3.connect('oreilly.sqlite')\n",
    "conn.execute(\"CREATE VIRTUAL TABLE books USING fts5(title,description);\")\n",
    "cur = conn.cursor()\n",
    "# poprawiÄ‡ prepare statements + escaping\n",
    "with open('oreilly.csv', 'r', encoding='utf-8',errors='ignore') as csvfile:\n",
    "    csv = csv.reader(csvfile,delimiter=',')\n",
    "    for row in csv:\n",
    "        cur.execute('INSERT INTO books(title,description) VALUES(\"'+re.escape(row[1])+'\",\"'+re.sub('\\\"',\"\",row[4])+'\");')\n",
    "        conn.commit()\n",
    "\n",
    "query = cur.execute(\"SELECT title FROM books LIMIT 0,10;\")\n",
    "print(cur.fetchall())\n",
    "#cur.execute(\"DROP TABLE books;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity measures\n",
    "\n",
    "There are plenty of methods to measure the similarity of strings. Two most popular Python libraries examples for such measure are shown. We compare two strings: trains and training. The SequenceMatcher class allow us to use the Gestalt pattern matching algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "a = \"training\"\n",
    "b = \"trains\"\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "ratio = SequenceMatcher(None, a, b).ratio()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance is a normalized value between 0 and 1, where 1 means identical.\n",
    "\n",
    "A different approach is shown below. We use the Jellyfish library. There are a few methods that we can use here. One of it is the Levenshtein distance. Below the distance and normalize distance values are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "distance = jellyfish.levenshtein_distance(a,b)\n",
    "print(distance)\n",
    "\n",
    "normalized_distance = distance/max(len(a),len(b))\n",
    "print(normalized_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite LIKE vs. Full-text search\n",
    "\n",
    "It unlikely to show SQL together with NLP methods for string comparison, but there are two features that are worth to mention. In the first cell, we connect to the SQLite database that we have created earlier in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('oreilly.sqlite')\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIKE keyword needs a % if we want to say that it can have any words before or after the sentence that we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT title FROM books WHERE description LIKE '%software%';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full-text search is a bit more intelligent as it calculated a score to accuracy of the text that we are looking for. There are plenty of such metrics. In SQLite we have bm25. We can use different combination of a term like do, does, doing and it will come to similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT title,bm25(books) FROM books WHERE books MATCH 'software' ORDER BY bm25(books) DESC;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP methods\n",
    "\n",
    "Three NLP methods that are helpful when buildingn a rule-based chatbots are:\n",
    "*tokenization,\n",
    "*lemmatization,\n",
    "*stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization works similar to split method known from the regular expression library, but there is at least one small difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example = \"A training example.\"\n",
    "import re\n",
    "\n",
    "pattern = \"\\\\s+\"\n",
    "words = re.split(pattern, example)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK is one the most known library for NLP. As many other suchn libraries, it contain a tokenizer does not only split the sentence, but also take punctuation marks as a separate part of a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokens = nltk.word_tokenize(example)\n",
    "print(\"Tokens: \" + str(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is a process of getting a basic form of a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize('do',pos='v'))\n",
    "print(wordnet_lemmatizer.lemmatize('does',pos='v'))\n",
    "print(wordnet_lemmatizer.lemmatize('doing',pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the word to it basic form depending on part of speech:\n",
    "ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "Stemming is similar to lemmatization, but the main difference is that is just reduce the word to it root. It gives in many cases different results than lemmatization as the second solution is based on part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, word_tokenize\n",
    "\n",
    "sample = \"This is a new training about machine learning usage for chatbots\"\n",
    "\n",
    "tokens = word_tokenize(sample)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "p_stem = [porter.stem(t) for t in tokens]\n",
    "print(p_stem)\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "l_stem = [lancaster.stem(t) for t in tokens]\n",
    "print(l_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based chatbot\n",
    "\n",
    "In this section we implement two examples of chatbots. The first one is a chatbot where the scenario is simple and the goal is to go through all questions and respond with an answer. The second chatbot is comparing the questions and gives appropriate responses based on text similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple scenario chatbot - Greg is your stock marker advisor\n",
    "\n",
    "This chatbot is a stock market advisor with a list of questions. The answers for these questions allow the chatbot to give a the stock value for a given date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "welcome = \"Hi! I'm Greg, your stock market advisor.\"\n",
    "\n",
    "questions = (\n",
    "    \"What stock exchange would like to check? Please provide the stock exchange symbol.\",\n",
    "    \"What stock from the stock exchange would like to check? Please use the stock index name.\",\n",
    "    \"What date are you interested in?\",\n",
    "    \"Should I print the maximum, minimum, opening or closing value? Choose one.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use here [Alpha Vantage](https://www.alphavantage.co/support/#api-key) to get the current stock value. You need to obtain the API key first and past it below into API_KEY variable. We simplify the date and choose it randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "\n",
    "API_KEY = \"\"\n",
    "URL = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=\"\n",
    "\n",
    "def get_stock_value(stock_request):\n",
    "    if stock_request[0].upper() != \"NYSE\":\n",
    "        return \"Stock exchange not supported\"\n",
    "    \n",
    "    resposne = requests.get(URL+stock_request[1]+ \"&apikey=\" + API_KEY)\n",
    "    stock_data = resposne.json()[\"Time Series (Daily)\"]\n",
    "    date = random.choice(list(stock_data.keys()))\n",
    "    answer = \"The stock \" + stock_request[3] +\" for \" + stock_request[1]+ \" on \" + stock_request[2] +\" is \"+ stock_data[date]['2. high']\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of the chatbot is written in just few lines. We loop over the questions and used it to get the stock details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def run_chatbot():\n",
    "    print(welcome)\n",
    "    answers = []\n",
    "    for question_id in range(len(questions)):\n",
    "        print(questions[question_id])\n",
    "        answer = input()\n",
    "        answers.append(answer)\n",
    "    print(get_stock_value(answers))\n",
    "    \n",
    "run_chatbot()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-based customer support chatbot\n",
    "\n",
    "In this case we also need to setup a welcome message and a list of questions. This time the questions are potential customer questions. We set also a list of answers for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "welcome = \"Hi! I'm Arthur, the customer support chatbot. How can I help you?\"\n",
    "\n",
    "questions = (\n",
    "    \"The app if freezing after I click run button\",\n",
    "    \"I don't know how to proceed with the invoice\",\n",
    "    \"I get an error when I try to install the app\",\n",
    "    \"It crash after I have updated it\",\n",
    "    \"I cannot login in to the app\",\n",
    "    \"I'm not able to download it\"\n",
    "            )\n",
    "\n",
    "answers = (\n",
    "        \"You need to clean up the cache. Please go to ...\",\n",
    "        \"Please go to Setting, next Subscriptions and there is the Billing section\",\n",
    "        \"Could you plese send the log files placed in ... to ...\",\n",
    "        \"Please restart your PC\",\n",
    "        \"Use the forgot password button to setup a new password\",\n",
    "        \"Probably you have an ad blocker plugin installed and it blocks the popup with the download link\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most questions will not be exactly the same as we have on our list, but can be similar. Let's define a function to measure the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "similarity_treshold = 0.2\n",
    "\n",
    "def get_highest_similarity(customer_question):\n",
    "    max_similarity = 0\n",
    "    highest_prob_index = 0\n",
    "    for question_id in range(len(questions)):\n",
    "        similarity = SequenceMatcher(None,customer_question,questions[question_id]).ratio()\n",
    "        #print(similarity)\n",
    "        if similarity > max_similarity:\n",
    "            highest_index = question_id\n",
    "            max_similarity = similarity\n",
    "    if max_similarity > similarity_treshold:\n",
    "        return answers[highest_index]\n",
    "    else:\n",
    "        return \"The issues has been saved. We will contact you soon.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part is just a few lines of code. You can print the similarities of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_chatbot():\n",
    "    print(welcome)\n",
    "    question = \"\"\n",
    "    while question != \"thank you\":\n",
    "        question = input()\n",
    "        answer = get_highest_similarity(question)\n",
    "        print(answer)\n",
    "    \n",
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 1: Build a rule-based chatbot.\n",
    "\n",
    "There is a list of questions below. Use different method of comparison to figure out which one gives the best results and why. Compare the above used methods with at least one of the following:\n",
    "- SQL full text search,\n",
    "- normalized Levenshtein distance,\n",
    "- tokenization and lemmatization and count the number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_treshold = 0.2\n",
    "\n",
    "def get_highest_similarity(customer_question):\n",
    "    max_similarity = 0\n",
    "    highest_prob_index = 0\n",
    "    for question_id in range(len(questions)):\n",
    "        # put your code here\n",
    "        similarity = 0 #\n",
    "        #print(similarity)\n",
    "        if similarity > max_similarity:\n",
    "            highest_index = question_id\n",
    "            max_similarity = similarity\n",
    "    if max_similarity > similarity_treshold:\n",
    "        return answers[highest_index]\n",
    "    else:\n",
    "        return \"The issues has been saved. We will contact you soon.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_chatbot():\n",
    "    print(welcome)\n",
    "    question = \"\"\n",
    "    while question != \"thank you\":\n",
    "        question = input()\n",
    "        answer = get_highest_similarity(question)\n",
    "        print(answer)\n",
    "    \n",
    "run_chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
